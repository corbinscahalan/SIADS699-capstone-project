{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import simplefilter\n",
    "simplefilter('ignore')\n",
    "from extract_video_info import extract_by_id\n",
    "from api_utils import linear_pop_metric\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resizing image to (256, 256) as this is the max size we will use. \n",
    "# converting now to save space but recording origional size as features\n",
    "def resize_image(image_path:str, new_size:tuple):\n",
    "    try:\n",
    "        image = Image.open(image_path)\n",
    "        resized_image = image.resize(new_size)\n",
    "    except (FileNotFoundError, OSError):\n",
    "        return np.nan, (np.nan, np.nan)\n",
    "        \n",
    "    image_name, ext = os.path.splitext(image_path)\n",
    "    image_name = image_name + '.jpg'\n",
    "    if resized_image.mode in (\"RGBA\", \"P\"): \n",
    "        resized_image = resized_image.convert(\"RGB\")\n",
    "    resized_image.save(image_name)\n",
    "    size = image.size\n",
    "    image.close()\n",
    "    if ext != '.jpg':\n",
    "        os.remove(image_path)\n",
    "    return os.path.split(image_name)[1], size\n",
    "\n",
    "\n",
    "def resize_images(image_name:str, image_folder:str, new_size:tuple=(256, 256)):\n",
    "    image_path = os.path.join(image_folder, image_name)\n",
    "    name, (width, height) = resize_image(image_path, new_size)\n",
    "    return pd.Series({'thumb_name': name, 'thumb_width': width, 'thumb_height': height})\n",
    "\n",
    "\n",
    "# takes a dataframe like that extracted by api_utils.py and adds features from youtube-dl tool including thumbnail image\n",
    "# will save over input file after each batch if save_after_each_batch=True, \n",
    "# otherwise it will not save the result and only return the result\n",
    "def continue_extraction(df_path:str, thumb_folder:str, batch_size:int=1000, batches:int=5, save_after_each_batch:bool=True):\n",
    "\n",
    "    df = pd.read_json(df_path)\n",
    "\n",
    "\n",
    "    extract_list = ['description', 'duration', 'age_limit', \n",
    "                    'categories', 'tags', 'is_live',\n",
    "                    'width', 'height', 'fps', 'vcodec', 'vbr', \n",
    "                    'acodec', 'abr', 'thumb_name', 'subtitles']\n",
    "    \n",
    "    thumb_cols = ['thumb_width', 'thumb_height']\n",
    "    if 'thumb_width' not in df.columns:\n",
    "        df.loc[:, thumb_cols] = np.nan\n",
    "    if 'subtitles' not in df.columns:\n",
    "        df.loc[:, extract_list] = np.nan\n",
    "\n",
    "    for batch in range(1, batches + 1):\n",
    "\n",
    "        indexes = df[((df['subtitles'].isnull()) & (df['thumb_name'].isnull()))].index[:batch_size]\n",
    "        print('getting data')\n",
    "        df.loc[indexes, extract_list] = df.loc[indexes, 'vid_id'].progress_apply(lambda x: extract_by_id(x, thumb_folder))\n",
    "        print('resizing images')\n",
    "        df.loc[indexes, ['thumb_name', 'thumb_width', 'thumb_height']] = df.loc[indexes, 'thumb_name'].progress_apply(lambda x: resize_images(x, thumb_folder))\n",
    "        \n",
    "        if save_after_each_batch:\n",
    "            print(f\"After batch: {batch} of {batches} Shape of extracted: {df[~df['subtitles'].isnull()].shape} Shape of unextracted: {df[df['subtitles'].isnull()].shape}\")\n",
    "            df.to_json(df_path)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "THUMB_FOLDER = ''\n",
    "\n",
    "df_path = ''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = continue_extraction(df_path, THUMB_FOLDER, 5000, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merges two dataframes. used for instances where there is an updated api_utils.py dataframe or the collection was running on multiple systems\n",
    "# in the instance where there is an updated api_utils.py dataframe it should be inputted as new_df,\n",
    "# order does not matter in the other situatuion\n",
    "\n",
    "def merge_dfs(orig_df, new_df, final_path):\n",
    "    df1 = pd.read_json(orig_df)\n",
    "    df1 = df1.drop_duplicates(subset='vid_id')\n",
    "\n",
    "    df2 = pd.read_json(new_df)\n",
    "    df2 = df2.drop_duplicates(subset='vid_id')\n",
    "\n",
    "    df1.set_index('vid_id', inplace=True, drop=True)\n",
    "    df2.set_index('vid_id', inplace=True, drop=True)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    extract_list = ['description', 'duration', 'age_limit', \n",
    "                    'categories', 'tags', 'is_live',\n",
    "                    'width', 'height', 'fps', 'vcodec', 'vbr', \n",
    "                    'acodec', 'abr', 'thumb_name', 'subtitles',\n",
    "                    'thumb_width', 'thumb_height']\n",
    "\n",
    "    if 'subtitles' not in df2.columns:\n",
    "        df2.loc[:, extract_list] = np.nan\n",
    "\n",
    "    print(df1[~df1['subtitles'].isnull()].shape)\n",
    "    print(df2[~df2['subtitles'].isnull()].shape)\n",
    "   \n",
    "    df2 = df2.fillna(df1).reset_index()\n",
    "\n",
    "    \n",
    "    print(df1[~df1['subtitles'].isnull()].shape)\n",
    "    print(df2[~df2['subtitles'].isnull()].shape)\n",
    "    df2.to_json(final_path)\n",
    "    return df1, df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(471329, 33)\n",
      "(441329, 33)\n",
      "(471329, 33)\n",
      "(546829, 34)\n"
     ]
    }
   ],
   "source": [
    "df1, df2 = merge_dfs('', '', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_json('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "from shutil import copyfile\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# this is used to clean the dataframe, i.e, remove nulls and ---missing--- tag in the subtitles and thumb_name columns\n",
    "# then applies the linear_pop_metric. it then shuffles the data and splits it. one set for both neural net models and \n",
    "# another for the ensemble models\n",
    "def data_clean_and_split(df, dest_folder, nn_ens_split:float=.8, save_data:bool=True):\n",
    "\n",
    "\n",
    "    df_ = df.copy()\n",
    "\n",
    "    print(df_.shape)\n",
    "    print('applying metric')\n",
    "    df_ = df.dropna(subset=['vid_likecount', 'vid_viewcount', 'vid_commentcount'])\n",
    "    df_ = df_.merge(linear_pop_metric(df_)[['vid_id', 'pop_metric']], on='vid_id')\n",
    "    df_ = df_.dropna(subset=['pop_metric'])\n",
    "    df_ = df_.dropna(subset=['subtitles', 'thumb_name'], how='all')\n",
    "    print('before split')\n",
    "    print(df_.shape)\n",
    "    df_ = df_.sample(df_.shape[0])\n",
    "\n",
    "    df_nn = df_.iloc[:int(nn_ens_split * df_.shape[0]), :]\n",
    "    df_ensemble = df_.iloc[int(nn_ens_split * df_.shape[0]):, :]\n",
    "    print('after split')\n",
    "    print(f'NN models data.shape {df_nn.shape}, ensemble model data.shape {df_ensemble.shape}')\n",
    "\n",
    "    drop_index_sub = df_nn[df_nn['subtitles'] == '---missing---'].index\n",
    "    drop_index_image = df_nn[df_nn['thumb_name'] == '---missing---'].index\n",
    "    drop_index_ensemble = df_ensemble[((df_ensemble['thumb_name'] == '---missing---') | (df_ensemble['subtitles'] == '---missing---'))].index\n",
    "    \n",
    "    df_cnn = df_nn.drop(drop_index_image, axis=0)\n",
    "    df_cnn.dropna(subset='thumb_name', inplace=True, axis=0)\n",
    "    df_rnn = df_nn.drop(drop_index_sub, axis=0)\n",
    "    df_rnn.dropna(subset='subtitles', inplace=True, axis=0)\n",
    "    df_ensemble = df_ensemble.drop(drop_index_ensemble, axis=0)\n",
    "    df_ensemble.dropna(subset=['thumb_name', 'subtitles'], inplace=True, axis=0)\n",
    "    \n",
    "    print('after drops')\n",
    "    print(df_cnn.shape, df_rnn.shape, df_ensemble.shape)\n",
    "\n",
    "    if save_data:\n",
    "        base_dest_path = Path(dest_folder)\n",
    "        df_cnn.to_json(str(base_dest_path / 'cnn_data.json.gz'))\n",
    "        df_rnn.to_json(str(base_dest_path / 'rnn_data.json.gz'))\n",
    "        df_ensemble.to_json(str(base_dest_path / 'ens_data.json.gz'))\n",
    "\n",
    "    return df_cnn, df_rnn, df_ensemble\n",
    "\n",
    "\n",
    "def split_images(nn_json_name:str, ens_json_name:str, source_folder:str, dest_folder:str):\n",
    "\n",
    "    source_path = Path(source_folder)\n",
    "    base_dest_path = Path(dest_folder)\n",
    "    conflict = base_dest_path / 'conflict'\n",
    "\n",
    "    nn_json_path = base_dest_path / nn_json_name\n",
    "    ens_json_path = base_dest_path / ens_json_name\n",
    "\n",
    "    nn_images_path = base_dest_path / 'nn_data' / 'images'\n",
    "\n",
    "    ens_images_path = base_dest_path / 'ens_train' / 'images'\n",
    "\n",
    "    paths = [nn_images_path, ens_images_path, conflict]\n",
    "\n",
    "    for p in paths:\n",
    "        p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    \n",
    "    \n",
    "    for dest, dataset_path in zip(paths[:2], [nn_json_path, ens_json_path]):\n",
    "        \n",
    "        dataset = pd.read_json(dataset_path)\n",
    "        counter = 0\n",
    "        files = dataset['thumb_name'].values\n",
    "        for file in tqdm_notebook(files):\n",
    "            try:\n",
    "                src = source_path / file\n",
    "                des = dest / file\n",
    "                copyfile(src, des)\n",
    "            except FileNotFoundError:\n",
    "                dataset.loc[dataset['thumb_name'] == file, ['thumb_name']] = np.nan\n",
    "\n",
    "                counter += 1\n",
    "\n",
    "        if dataset['thumb_name'].isnull().sum() > 0:\n",
    "            print(f'discrepancy found {counter} missing files. saving new data')\n",
    "            dataset = dataset.dropna(subset='thumb_name')\n",
    "            dataset.to_json(conflict / ('-' + dataset_path.name))\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1120959, 34)\n",
      "applying metric\n",
      "before split\n",
      "(554177, 35)\n",
      "after split\n",
      "NN models data.shape (443341, 35), ensemble model data.shape (110836, 35)\n",
      "(428023, 35) (293475, 35) (71233, 35)\n"
     ]
    }
   ],
   "source": [
    "df_cnn, df_rnn, df_ensemble = data_clean_and_split(df2, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vid_id                  0\n",
       "chan_query              0\n",
       "chan_id                 0\n",
       "chan_name               0\n",
       "chan_viewcount          0\n",
       "chan_subcount           0\n",
       "chan_start_dt           0\n",
       "chan_thumb              0\n",
       "chan_vidcount           0\n",
       "vid_name                0\n",
       "vid_publish_dt          0\n",
       "vid_thumb               0\n",
       "vid_duration            0\n",
       "vid_caption             0\n",
       "vid_viewcount           0\n",
       "vid_likecount           0\n",
       "vid_commentcount        0\n",
       "description          1349\n",
       "duration                0\n",
       "age_limit               0\n",
       "categories              0\n",
       "tags                    0\n",
       "is_live             71233\n",
       "width                   1\n",
       "height                  1\n",
       "fps                     1\n",
       "vcodec                  0\n",
       "vbr                 10636\n",
       "acodec                  0\n",
       "abr                    27\n",
       "thumb_name              0\n",
       "subtitles               0\n",
       "thumb_width             0\n",
       "thumb_height            0\n",
       "pop_metric              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ensemble.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vid_id                   0\n",
       "chan_query               0\n",
       "chan_id                  0\n",
       "chan_name                0\n",
       "chan_viewcount           0\n",
       "chan_subcount            0\n",
       "chan_start_dt            0\n",
       "chan_thumb               0\n",
       "chan_vidcount            0\n",
       "vid_name                 0\n",
       "vid_publish_dt           0\n",
       "vid_thumb                0\n",
       "vid_duration             0\n",
       "vid_caption              0\n",
       "vid_viewcount            0\n",
       "vid_likecount            0\n",
       "vid_commentcount         0\n",
       "description           9715\n",
       "duration                 0\n",
       "age_limit                0\n",
       "categories               0\n",
       "tags                     0\n",
       "is_live             428023\n",
       "width                    0\n",
       "height                   0\n",
       "fps                      0\n",
       "vcodec                   0\n",
       "vbr                  62352\n",
       "acodec                   0\n",
       "abr                    163\n",
       "thumb_name               0\n",
       "subtitles             8612\n",
       "thumb_width              0\n",
       "thumb_height             0\n",
       "pop_metric               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cnn.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vid_id                   0\n",
       "chan_query               0\n",
       "chan_id                  0\n",
       "chan_name                0\n",
       "chan_viewcount           0\n",
       "chan_subcount            0\n",
       "chan_start_dt            0\n",
       "chan_thumb               0\n",
       "chan_vidcount            0\n",
       "vid_name                 0\n",
       "vid_publish_dt           0\n",
       "vid_thumb                0\n",
       "vid_duration             0\n",
       "vid_caption              0\n",
       "vid_viewcount            0\n",
       "vid_likecount            0\n",
       "vid_commentcount         0\n",
       "description           5433\n",
       "duration                 0\n",
       "age_limit                0\n",
       "categories               0\n",
       "tags                     0\n",
       "is_live             293475\n",
       "width                    0\n",
       "height                   0\n",
       "fps                      0\n",
       "vcodec                   0\n",
       "vbr                  43059\n",
       "acodec                   0\n",
       "abr                     84\n",
       "thumb_name            8232\n",
       "subtitles                0\n",
       "thumb_width           8232\n",
       "thumb_height          8232\n",
       "pop_metric               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rnn.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaa0ca9d5c524d7aba99bf7b2ac2721d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/428023 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34cf49014354432caa0b2a922297ff6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71233 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "split_images('', '', '', '')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('capstone_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2b9192579c383e93a0fe4ed71cd54054db34618ad79690d6950dc3424d2ec03d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
